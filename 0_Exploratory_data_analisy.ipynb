{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **IMPORTS/CONFIGURAÇÕES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Bibliotecas padrão para manipulação do sistema operacional\n",
    "import os\n",
    "# Bibliotecas para manipulação de dados\n",
    "import pandas as pd  # Manipulação de dados tabulares\n",
    "# Bibliotecas próprias\n",
    "from PROJECT_LIBRARY.Data_extraction import *  # Biblioteca própria para extração dos dados\n",
    "from PROJECT_LIBRARY.Data_transformation import *  # Biblioteca própria para transformação dos dados\n",
    "# Biblioteca de avisos\n",
    "import warnings\n",
    "\n",
    "\n",
    "# Configurações\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_colwidth = None\n",
    "pd.options.display.float_format = lambda x: f'{x:,.2f}'\n",
    "px.defaults.template = 'plotly_dark'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LOAD**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "Já que há vários arquivos, um para cada ano, deve-se verificar a padronização de apresentação dos dados por arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E_FPE', 'E_FPM', 'E_IPI', 'E_ITR', 'E_COUN_VAAF', 'E_COUN_VAAT', 'E_COUN_VAAR', 'E_ICMS', 'E_IPVA', 'E_ITCMD', 'E_Tot1_U', 'E_Tot2_E', 'E_TOTAL', 'M_FPE', 'M_FPM', 'M_IPI', 'M_ITR', 'M_COUN_VAAF', 'M_COUN_VAAT', 'M_COUN_VAAR', 'M_ICMS', 'M_IPVA', 'M_ITCMD', 'M_Tot1_U', 'M_Tot2_E', 'M_TOTAL', 'Resumo']\n"
     ]
    }
   ],
   "source": [
    "# Identificando todas as abas de ultimo arquivo\n",
    "sheet_names = xlrd.open_workbook(filename=f'./RAW_DATAS/Fundeb 2024.xls').sheet_names()\n",
    "print(sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fundeb 2007.xls 25 ['E_FPE', 'E_FPM', 'E_IPI', 'E_COUN', 'E_LC8796', 'E_ITR', 'E_ICMS', 'E_IPVA', 'E_ITCMD', 'E_Tot1_U', 'E_Tot2_E', 'E_TOTAL', 'M_FPE', 'M_FPM', 'M_IPI', 'M_COUN', 'M_LC8796', 'M_ITR', 'M_ICMS', 'M_IPVA', 'M_ITCMD', 'M_Tot1_U', 'M_Tot2_E', 'M_TOTAL', 'Resumo']\n",
      "Fundeb 2008.xls 25 ['E_FPE', 'E_FPM', 'E_IPI', 'E_COUN', 'E_LC8796', 'E_ITR', 'E_ICMS', 'E_IPVA', 'E_ITCMD', 'E_Tot1_U', 'E_Tot2_E', 'E_TOTAL', 'M_FPE', 'M_FPM', 'M_IPI', 'M_COUN', 'M_LC8796', 'M_ITR', 'M_ICMS', 'M_IPVA', 'M_ITCMD', 'M_Tot1_U', 'M_Tot2_E', 'M_TOTAL', 'Resumo']\n",
      "Fundeb 2009.xls 25 ['E_FPE', 'E_FPM', 'E_IPI', 'E_COUN', 'E_LC8796', 'E_ITR', 'E_ICMS', 'E_IPVA', 'E_ITCMD', 'E_Tot1_U', 'E_Tot2_E', 'E_TOTAL', 'M_FPE', 'M_FPM', 'M_IPI', 'M_COUN', 'M_LC8796', 'M_ITR', 'M_ICMS', 'M_IPVA', 'M_ITCMD', 'M_Tot1_U', 'M_Tot2_E', 'M_TOTAL', 'Resumo']\n",
      "Fundeb 2010.xls 25 ['E_FPE', 'E_FPM', 'E_IPI', 'E_COUN', 'E_LC8796', 'E_ITR', 'E_ICMS', 'E_IPVA', 'E_ITCMD', 'E_Tot1_U', 'E_Tot2_E', 'E_TOTAL', 'M_FPE', 'M_FPM', 'M_IPI', 'M_COUN', 'M_LC8796', 'M_ITR', 'M_ICMS', 'M_IPVA', 'M_ITCMD', 'M_Tot1_U', 'M_Tot2_E', 'M_TOTAL', 'Resumo']\n",
      "Fundeb 2011.xls 25 ['E_FPE', 'E_FPM', 'E_IPI', 'E_COUN', 'E_LC8796', 'E_ITR', 'E_ICMS', 'E_IPVA', 'E_ITCMD', 'E_Tot1_U', 'E_Tot2_E', 'E_TOTAL', 'M_FPE', 'M_FPM', 'M_IPI', 'M_COUN', 'M_LC8796', 'M_ITR', 'M_ICMS', 'M_IPVA', 'M_ITCMD', 'M_Tot1_U', 'M_Tot2_E', 'M_TOTAL', 'Resumo']\n",
      "Fundeb 2012.xls 27 ['E_FPE', 'E_FPM', 'E_IPI', 'E_COUN', 'E_LC8796', 'E_ITR', 'E_ICMS', 'E_IPVA', 'E_ITCMD', 'E_Tot1_U', 'E_Tot2_E', 'E_Ajuste', 'E_TOTAL', 'M_FPE', 'M_FPM', 'M_IPI', 'M_COUN', 'M_LC8796', 'M_ITR', 'M_ICMS', 'M_IPVA', 'M_ITCMD', 'M_Tot1_U', 'M_Tot2_E', 'M_Ajuste', 'M_TOTAL', 'Resumo']\n",
      "Fundeb 2013.xls 27 ['E_FPE', 'E_FPM', 'E_IPI', 'E_COUN', 'E_LC8796', 'E_ITR', 'E_ICMS', 'E_IPVA', 'E_ITCMD', 'E_Tot1_U', 'E_Tot2_E', 'E_Ajuste', 'E_TOTAL', 'M_FPE', 'M_FPM', 'M_IPI', 'M_COUN', 'M_LC8796', 'M_ITR', 'M_ICMS', 'M_IPVA', 'M_ITCMD', 'M_Tot1_U', 'M_Tot2_E', 'M_Ajuste', 'M_TOTAL', 'Resumo']\n",
      "Fundeb 2014.xls 27 ['E_FPE', 'E_FPM', 'E_IPI', 'E_COUN', 'E_LC8796', 'E_ITR', 'E_ICMS', 'E_IPVA', 'E_ITCMD', 'E_Tot1_U', 'E_Tot2_E', 'E_Ajuste', 'E_TOTAL', 'M_FPE', 'M_FPM', 'M_IPI', 'M_COUN', 'M_LC8796', 'M_ITR', 'M_ICMS', 'M_IPVA', 'M_ITCMD', 'M_Tot1_U', 'M_Tot2_E', 'M_Ajuste', 'M_TOTAL', 'Resumo']\n",
      "Fundeb 2015.xls 27 ['E_FPE', 'E_FPM', 'E_IPI', 'E_COUN', 'E_LC8796', 'E_ITR', 'E_ICMS', 'E_IPVA', 'E_ITCMD', 'E_Tot1_U', 'E_Tot2_E', 'E_Ajuste', 'E_TOTAL', 'M_FPE', 'M_FPM', 'M_IPI', 'M_COUN', 'M_LC8796', 'M_ITR', 'M_ICMS', 'M_IPVA', 'M_ITCMD', 'M_Tot1_U', 'M_Tot2_E', 'M_Ajuste', 'M_TOTAL', 'Resumo']\n",
      "Fundeb 2016.xls 27 ['E_FPE', 'E_FPM', 'E_IPI', 'E_COUN', 'E_LC8796', 'E_ITR', 'E_ICMS', 'E_IPVA', 'E_ITCMD', 'E_Tot1_U', 'E_Tot2_E', 'E_Ajuste', 'E_TOTAL', 'M_FPE', 'M_FPM', 'M_IPI', 'M_COUN', 'M_LC8796', 'M_ITR', 'M_ICMS', 'M_IPVA', 'M_ITCMD', 'M_Tot1_U', 'M_Tot2_E', 'M_Ajuste', 'M_TOTAL', 'Resumo']\n",
      "Fundeb 2017.xls 27 ['E_FPE', 'E_FPM', 'E_IPI', 'E_COUN', 'E_LC8796', 'E_ITR', 'E_ICMS', 'E_IPVA', 'E_ITCMD', 'E_Tot1_U', 'E_Tot2_E', 'E_Ajuste', 'E_TOTAL', 'M_FPE', 'M_FPM', 'M_IPI', 'M_COUN', 'M_LC8796', 'M_ITR', 'M_ICMS', 'M_IPVA', 'M_ITCMD', 'M_Tot1_U', 'M_Tot2_E', 'M_Ajuste', 'M_TOTAL', 'Resumo']\n",
      "Fundeb 2018.xls 27 ['E_FPE', 'E_FPM', 'E_IPI', 'E_COUN', 'E_LC8796', 'E_ITR', 'E_ICMS', 'E_IPVA', 'E_ITCMD', 'E_Tot1_U', 'E_Tot2_E', 'E_Ajuste', 'E_TOTAL', 'M_FPE', 'M_FPM', 'M_IPI', 'M_LC8796', 'M_ITR', 'M_ICMS', 'M_COUN', 'M_IPVA', 'M_ITCMD', 'M_Tot1_U', 'M_Tot2_E', 'M_Ajuste', 'M_TOTAL', 'Resumo']\n",
      "Fundeb 2019.xls 27 ['E_FPE', 'E_FPM', 'E_IPI', 'E_COUN', 'E_LC8796', 'E_ITR', 'E_ICMS', 'E_IPVA', 'E_ITCMD', 'E_Tot1_U', 'E_Tot2_E', 'E_Ajuste', 'E_TOTAL', 'M_FPE', 'M_FPM', 'M_IPI', 'M_LC8796', 'M_ITR', 'M_ICMS', 'M_COUN', 'M_IPVA', 'M_ITCMD', 'M_Tot1_U', 'M_Tot2_E', 'M_Ajuste', 'M_TOTAL', 'Resumo']\n",
      "Fundeb 2020.xls 25 ['E_FPE', 'E_FPM', 'E_IPI', 'E_COUN', 'E_LC8796', 'E_ITR', 'E_ICMS', 'E_IPVA', 'E_ITCMD', 'E_Tot1_U', 'E_Tot2_E', 'E_TOTAL', 'M_FPE', 'M_FPM', 'M_IPI', 'M_LC8796', 'M_ITR', 'M_ICMS', 'M_COUN', 'M_IPVA', 'M_ITCMD', 'M_Tot1_U', 'M_Tot2_E', 'M_TOTAL', 'Resumo']\n",
      "Fundeb 2021.xls 27 ['E_FPE', 'E_FPM', 'E_IPI', 'E_COUN_VAAF', 'E_LC8796', 'E_COUN_VAAT', 'E_ITR', 'E_ICMS', 'E_IPVA', 'E_ITCMD', 'E_Tot1_U', 'E_Tot2_E', 'E_TOTAL', 'M_FPE', 'M_FPM', 'M_IPI', 'M_LC8796', 'M_ITR', 'M_COUN_VAAF', 'M_COUN_VAAT', 'M_ICMS', 'M_IPVA', 'M_ITCMD', 'M_Tot1_U', 'M_Tot2_E', 'M_TOTAL', 'Resumo']\n",
      "Fundeb 2022.xls 27 ['E_FPE', 'E_FPM', 'E_IPI', 'E_AFE_EC123', 'E_ITR', 'E_COUN_VAAF', 'E_COUN_VAAT', 'E_ICMS', 'E_IPVA', 'E_ITCMD', 'E_Tot1_U', 'E_Tot2_E', 'E_TOTAL', 'M_FPE', 'M_FPM', 'M_IPI', 'M_AFE_EC123', 'M_ITR', 'M_COUN_VAAF', 'M_COUN_VAAT', 'M_ICMS', 'M_IPVA', 'M_ITCMD', 'M_Tot1_U', 'M_Tot2_E', 'M_TOTAL', 'Resumo']\n",
      "Fundeb 2023.xls 27 ['E_FPE', 'E_FPM', 'E_IPI', 'E_ITR', 'E_COUN_VAAF', 'E_COUN_VAAT', 'E_COUN_VAAR', 'E_ICMS', 'E_IPVA', 'E_ITCMD', 'E_Tot1_U', 'E_Tot2_E', 'E_TOTAL', 'M_FPE', 'M_FPM', 'M_IPI', 'M_ITR', 'M_COUN_VAAF', 'M_COUN_VAAT', 'M_COUN_VAAR', 'M_ICMS', 'M_IPVA', 'M_ITCMD', 'M_Tot1_U', 'M_Tot2_E', 'M_TOTAL', 'Resumo']\n",
      "Fundeb 2024.xls 27 ['E_FPE', 'E_FPM', 'E_IPI', 'E_ITR', 'E_COUN_VAAF', 'E_COUN_VAAT', 'E_COUN_VAAR', 'E_ICMS', 'E_IPVA', 'E_ITCMD', 'E_Tot1_U', 'E_Tot2_E', 'E_TOTAL', 'M_FPE', 'M_FPM', 'M_IPI', 'M_ITR', 'M_COUN_VAAF', 'M_COUN_VAAT', 'M_COUN_VAAR', 'M_ICMS', 'M_IPVA', 'M_ITCMD', 'M_Tot1_U', 'M_Tot2_E', 'M_TOTAL', 'Resumo']\n"
     ]
    }
   ],
   "source": [
    "# Identificando todas as abas de todos os arquivos\n",
    "directory = './RAW_DATAS'\n",
    "file_names = sorted(os.listdir(path=directory))\n",
    "\n",
    "for file_name in file_names:\n",
    "    sheet_names = xlrd.open_workbook(filename=f'{directory}/{file_name}').sheet_names()\n",
    "    print(file_name, len(sheet_names), sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E_FPE',\n",
       " 'E_FPM',\n",
       " 'E_IPI',\n",
       " 'E_COUN',\n",
       " 'E_LC8796',\n",
       " 'E_ITR',\n",
       " 'E_ICMS',\n",
       " 'E_IPVA',\n",
       " 'E_ITCMD',\n",
       " 'E_Tot1_U',\n",
       " 'E_Tot2_E',\n",
       " 'E_TOTAL',\n",
       " 'M_FPE',\n",
       " 'M_FPM',\n",
       " 'M_IPI',\n",
       " 'M_COUN',\n",
       " 'M_LC8796',\n",
       " 'M_ITR',\n",
       " 'M_ICMS',\n",
       " 'M_IPVA',\n",
       " 'M_ITCMD',\n",
       " 'M_Tot1_U',\n",
       " 'M_Tot2_E',\n",
       " 'M_TOTAL',\n",
       " 'Resumo',\n",
       " 'E_Ajuste',\n",
       " 'M_Ajuste',\n",
       " 'E_COUN_VAAF',\n",
       " 'E_COUN_VAAT',\n",
       " 'M_COUN_VAAF',\n",
       " 'M_COUN_VAAT',\n",
       " 'E_AFE_EC123',\n",
       " 'M_AFE_EC123',\n",
       " 'E_COUN_VAAR',\n",
       " 'M_COUN_VAAR']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Função criada para extração dos nomes de todas as abas do arquivo excel que é emitidos por ano\n",
    "def get_all_sheet_names_on_files(fold):\n",
    "    # Lista ordenada de todos os nomes dos arquivos dentro da pasta dados\n",
    "    file_names = sorted(os.listdir(path=fold))\n",
    "    # Gerando uma lista com o nome de todas as abas únicas que existem em todos os arquivos\n",
    "    all_sheet_names = []\n",
    "    for file_name in file_names:\n",
    "        # Listando o nome de todas as abas dentro de um arquivo constante dentro da pasta\n",
    "        sheet_names = xlrd.open_workbook(\n",
    "            filename=f'{fold}/{file_name}').sheet_names()\n",
    "        for sheet_name in sheet_names:\n",
    "            # Adicionando o nome da aba do arquivo dentro de lista casa ainda não esteja dentro\n",
    "            if sheet_name not in all_sheet_names:\n",
    "                all_sheet_names.append(sheet_name)\n",
    "    # Retornando uma lista ordenada de todos os nomes dos arquivos dentro da pasta dados\n",
    "    return all_sheet_names\n",
    "\n",
    "\n",
    "get_all_sheet_names_on_files('./RAW_DATAS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descrições\n",
    "- Inicialmente, de 2007 a 2011, as planilhas são compostas por 25 abas.\n",
    "- A partir de 2012 a 2019 se vê a adição de duas abas denominadas \"E_Ajuste\" e \"M_Ajuste\", mudando de 25 para 27 abas. \n",
    "- Em 2020, as abas de ajustes são integradas nas abas dos recursos, reduziando o numero de abas para 25 novamente, entretanto, praticamente, dobrando a quantidade de tabelas. Estão inclusos nesta planilha os valores do ajuste estabelecido pela Portaria Interministerial MEC/ME nº 2, de 10 de agosto de 2020 e os valores do ajuste estabelecido pela Portaria Interministerial MEC/ME nº 3, de 25 de novembro de 2020. A partir de então, requer-se um tratamento diferenciado dos dados.\n",
    "- Logo após, em 2021, 'E_COUN' é subdividida em 'E_COUN_VAAF' e 'E_COUN_VAAT', assim como 'M_COUN' para 'M_COUN_VAFF' e 'M_COUN_VAAT', retornando o numero de abas para 27. Estão inclusos nesta planilha os valores do ajuste da complementação da União previsto na Portaria Interministerial nº 3 , de 24 de maio de 2020.\n",
    "- Em 2022, são removidas as aba 'E_LC8796' e 'M_LC8796' e adicionadas as 'E_AFE_EC123' e 'M_AFE_EC123', mantendo o número de abas em 27. Estão inclusos nesta planilha os valores do ajuste.\n",
    "- E por fim, em 2023, as abas 'E_AFE_EC123' e 'M_AFE_EC123' são removidas e a entram as novas abas 'E_COUNT_VAAR' e 'M_COUNT_VAAR', mantendo o número de abas em 27. Estão inclusos nesta planilha os valores do ajuste.\n",
    "\n",
    "Dentre as colunas presentes nos dados, não serão necessárias: 'E_Tot1_U', 'E_Tot2_E', 'E_TOTAL', 'M_Tot1_U', 'M_Tot2_E', 'M_TOTAL', 'Resumo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento dos dados por ano até de 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de tratamento dos dados do fundeb de até de 2019\n",
    "def preprocessing_data_until_2019(io, sheet_name, skiprows, header):\n",
    "    # leitura do arquivo\n",
    "    df01 = pd.read_excel(io=io, sheet_name=sheet_name,\n",
    "                         skiprows=skiprows, header=header)\n",
    "    # Ajustes nos nomes das colunas\n",
    "    df01.columns = [i.strip() for i in df01.columns]\n",
    "    # Remoção da coluna total\n",
    "    df01 = df01.drop(columns='TOTAL')\n",
    "    # Remoção das linhas com valores nulos na coluna UF\n",
    "    df01 = df01.dropna(axis='rows', subset='UF')\n",
    "    df01 = df01.loc[df01.UF.str.len() == 2]\n",
    "    # Substituição dos valores nulos por 0\n",
    "    df01 = df01.fillna(0)\n",
    "    # Reconfiguração dos dados para uma tabela onde constem apenas as variáveis UF, COMPETÊNCIA e o NOME DA ABA DO ARQUIVO\n",
    "    df01 = pd.melt(\n",
    "        frame=df01,\n",
    "        id_vars=['UF'],\n",
    "        value_vars=['JANEIRO', 'FEVEREIRO', 'MARÇO', 'ABRIL', 'MAIO', 'JUNHO',\n",
    "                    'JULHO', 'AGOSTO', 'SETEMBRO', 'OUTUBRO', 'NOVEMBRO', 'DEZEMBRO'],\n",
    "        var_name='COMPETÊNCIA',\n",
    "        value_name=f'{sheet_name}')\n",
    "    # Ajuste do valores mensais para paríodos de tempo de acordo com o mês e o ano do arquivo\n",
    "    ano = re.findall(pattern=r'\\d+', string=io)[0]\n",
    "    map_months = {'JANEIRO': '1', 'FEVEREIRO': '2', 'MARÇO': '3', 'ABRIL': '4', 'MAIO': '5', 'JUNHO': '6',\n",
    "                  'JULHO': '7', 'AGOSTO': '8', 'SETEMBRO': '9', 'OUTUBRO': '10', 'NOVEMBRO': '11', 'DEZEMBRO': '12'}\n",
    "    df01['COMPETÊNCIA'] = pd.to_datetime(\n",
    "        arg=df01['COMPETÊNCIA'].map(map_months)+f'/{ano}', format=f'%m/%Y')\n",
    "    # Ordenamento dos dados para UF e COMPETÊNCIA\n",
    "    df01 = df01.sort_values(by=['UF', 'COMPETÊNCIA']).reset_index(drop=True)\n",
    "    return df01\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento dos dados por ano a partir de 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de tratamento dos dados de 2020 em diante\n",
    "def preprocessing_data_from_2020_onwards(io, sheet_name, skiprows, header):\n",
    "    # leitura do arquivo das tabelas principais\n",
    "    df01 = pd.read_excel(io=io, sheet_name=sheet_name,\n",
    "                         skiprows=skiprows, header=header, nrows=30)\n",
    "    df02 = pd.read_excel(io=io, sheet_name=sheet_name,\n",
    "                         skiprows=skiprows+39, header=header, nrows=30)\n",
    "    # Ajustes nos nomes das colunas\n",
    "    df01.columns = [i.strip() for i in df01.columns]\n",
    "    df02.columns = [i.strip() for i in df02.columns]\n",
    "    # Remoção da coluna total\n",
    "    df01 = df01.drop(columns='TOTAL')\n",
    "    df02 = df02.drop(columns='TOTAL')\n",
    "    # Remoção das linhas com valores nulos na coluna UF\n",
    "    df01 = df01.dropna(axis='rows', subset='UF')\n",
    "    df02 = df02.dropna(axis='rows', subset='UF')\n",
    "    # Substituição dos valores nulos por 0\n",
    "    df01 = df01.fillna(0)\n",
    "    df02 = df02.fillna(0)\n",
    "    # Reconfiguração dos dados para uma tabela onde constem apenas as variáveis UF, COMPETÊNCIA e o NOME DA ABA DO ARQUIVO\n",
    "    df01 = pd.melt(\n",
    "        frame=df01,\n",
    "        id_vars=['UF'],\n",
    "        value_vars=['JANEIRO', 'FEVEREIRO', 'MARÇO', 'ABRIL', 'MAIO', 'JUNHO',\n",
    "                    'JULHO', 'AGOSTO', 'SETEMBRO', 'OUTUBRO', 'NOVEMBRO', 'DEZEMBRO'],\n",
    "        var_name='COMPETÊNCIA',\n",
    "        value_name=f'{sheet_name}')\n",
    "    df02 = pd.melt(\n",
    "        frame=df02,\n",
    "        id_vars=['UF'],\n",
    "        value_vars=['JANEIRO', 'FEVEREIRO', 'MARÇO', 'ABRIL', 'MAIO', 'JUNHO',\n",
    "                    'JULHO', 'AGOSTO', 'SETEMBRO', 'OUTUBRO', 'NOVEMBRO', 'DEZEMBRO'],\n",
    "        var_name='COMPETÊNCIA',\n",
    "        value_name='A_'+f'{sheet_name}')\n",
    "    # Ajuste do valores mensais para paríodos de tempo de acordo com o mês e o ano do arquivo\n",
    "    map_months = {'JANEIRO': '1', 'FEVEREIRO': '2', 'MARÇO': '3', 'ABRIL': '4', 'MAIO': '5', 'JUNHO': '6',\n",
    "                  'JULHO': '7', 'AGOSTO': '8', 'SETEMBRO': '9', 'OUTUBRO': '10', 'NOVEMBRO': '11', 'DEZEMBRO': '12'}\n",
    "    ano = re.findall(pattern=r'\\d+', string=io)[0]\n",
    "    df01['COMPETÊNCIA'] = pd.to_datetime(\n",
    "        arg=df01['COMPETÊNCIA'].map(map_months)+f'/{ano}', format=f'%m/%Y')\n",
    "    df02['COMPETÊNCIA'] = pd.to_datetime(\n",
    "        arg=df02['COMPETÊNCIA'].map(map_months)+f'/{ano}', format=f'%m/%Y')\n",
    "    # Ordenamento dos dados para UF e COMPETÊNCIA\n",
    "    df01 = df01.sort_values(by=['UF', 'COMPETÊNCIA']).reset_index(drop=True)\n",
    "    df02 = df02.sort_values(by=['UF', 'COMPETÊNCIA']).reset_index(drop=True)\n",
    "    return df01, df02\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados 01 (Consolidado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de automatização do tratamento de todos os dados dentro de uma pasta\n",
    "def consolidation_data(fold):\n",
    "    # Captando lista de todoas os nomes de abas dentro dos arquivos\n",
    "    all_sheet_names = get_all_sheet_names_on_files(fold)\n",
    "    # Lista de nome de abas que serão removidas\n",
    "    remove_sheet_names = ['E_Tot1_U', 'E_Tot2_E', 'E_TOTAL',\n",
    "                          'M_Tot1_U', 'M_Tot2_E', 'M_TOTAL', 'Resumo']\n",
    "    # Gerando nova lista com o nome de todas as abas úteis\n",
    "    useful_sheet_names = [\n",
    "        iten for iten in all_sheet_names if iten not in remove_sheet_names]\n",
    "    # Iniciando lista para armazenar os dataframes das planilhas de cada aba\n",
    "    sheet_datas = []\n",
    "    # Gerando dataframe onde serão agrupadas todas as abas de um arquivo\n",
    "    sheet_datas_merged = pd.DataFrame({'UF': [], 'COMPETÊNCIA': []})\n",
    "    # Iniciando lista para armazenar todas os dataframes agrupados de cada arquivo\n",
    "    file_datas = []\n",
    "    # Loop para percorrer todos os arquivos dentro da pasta selecionada\n",
    "    file_names = sorted(os.listdir(path=fold))\n",
    "    for file in file_names:\n",
    "        # Loop para percorrer todas as abas úteis que constam dentro do arquivo\n",
    "        for sheet_name in useful_sheet_names:\n",
    "            # Trasnformação para cada arquivo com dados até 2019\n",
    "            if int(re.findall(pattern=r'\\d+', string=file)[0]) <= 2019:\n",
    "                # Tentar ler o arquivo com as abas úteis, caso a aba não exista no arquivo, será analisada aba seguinte da lista de abas úteis\n",
    "                try:\n",
    "                    # Tentar ler o arquivo após 9 linhas, caso contrário, lerá após 7 linhas\n",
    "                    try:\n",
    "                        df01 = preprocessing_data_until_2019(\n",
    "                            io=f'{fold}/{file}', sheet_name=sheet_name, skiprows=9, header=0)\n",
    "                        sheet_datas.append(df01)\n",
    "                    except:\n",
    "                        df01 = preprocessing_data_until_2019(\n",
    "                            io=f'{fold}/{file}', sheet_name=sheet_name, skiprows=7, header=0)\n",
    "                        sheet_datas.append(df01)\n",
    "                except:\n",
    "                    pass\n",
    "            # Transformação para cada arquivo com dados de 2020 em diante\n",
    "            elif int(re.findall(pattern=r'\\d+', string=file)[0]) >= 2020:\n",
    "                # Tentar ler o arquivo com as abas úteis, caso a aba não exista no arquivo, será analisada aba seguinte da lista de abas úteis\n",
    "                try:\n",
    "                    df01, df_ajuste = preprocessing_data_from_2020_onwards(\n",
    "                        io=f'{fold}/{file}', sheet_name=sheet_name, skiprows=7, header=0)\n",
    "                    sheet_datas.append(df01)\n",
    "                    sheet_datas.append(df_ajuste)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "        # Loop de consolidação de todos os dataframes de cada aba de um arquivo\n",
    "        for sheet_data in sheet_datas:\n",
    "            # Consolidação de cada dataframe gerado com o posterior arquivodo na lista de dataframes\n",
    "            sheet_datas_merged = pd.merge(left=sheet_datas_merged, right=sheet_data, on=[\n",
    "                                          'UF', 'COMPETÊNCIA'], how='outer')\n",
    "        # adição da consolidação de todas as abas de um arquivo a lista de dataframes agrupados\n",
    "        file_datas.append(sheet_datas_merged)\n",
    "        # Reinicialização da lista sheet_datas para armazenamento das abas do proximo arquivo\n",
    "        sheet_datas = []\n",
    "        # Reinicialização dos dataframes agrupados para o o agrupamento do próximo arquivo\n",
    "        sheet_datas_merged = pd.DataFrame({'UF': [], 'COMPETÊNCIA': []})\n",
    "    # Concatenação de todos os dataframes agrupados de cada arquivo\n",
    "    df01 = pd.concat(file_datas, axis='rows')\n",
    "    # Substituição de valores nulos por 0\n",
    "    df01 = df01.fillna(0)\n",
    "    # Reorganização do index para a variável COMPETÊNCIA\n",
    "    df01 = df01.set_index(keys='COMPETÊNCIA', drop=True)\n",
    "    # Ordenamento das variáveis por ordem alfabética\n",
    "    df01 = df01[sorted(df01.columns)]\n",
    "    df01 = df01.reset_index()\n",
    "    df01.to_parquet('./DATASETS/consolidated_data.parquet')\n",
    "    return df01\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados 02 (Sumarizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumarização dos dados (Competência, uf, esfera, descrição, repasse, total)\n",
    "def summarization_data(fold):\n",
    "    df = consolidation_data(fold=fold)\n",
    "    # Nome das variáveis numéricas decimais\n",
    "    num_vars = df.dtypes[(df.dtypes.values == 'float64')].index\n",
    "    # Convertendo colunas para uma variável\n",
    "    df_melted = df.melt(id_vars=[\n",
    "                        'COMPETÊNCIA', 'UF'], value_vars=num_vars, var_name='DESCRIÇÃO', value_name='TOTAL')\n",
    "    # Criando coluna \"Esfera\"\n",
    "    df_melted['ESFERA'] = df_melted['DESCRIÇÃO'].map(lambda x: 'Estadual' if (\n",
    "        x.startswith('E')) or (x.startswith('A_E')) else 'Municipal')\n",
    "    # Criando coluna do tipo de repasse\n",
    "    df_melted['TIPO DE REPASSE'] = df_melted['DESCRIÇÃO'].map(\n",
    "        lambda x: 'TOTAL LIQUIDO' if (x.startswith('E')) or (x.startswith('M')) else 'TOTAL AJUSTE')\n",
    "    # Criando coluna do nome do repasse\n",
    "    df_melted['REPASSE'] = df_melted['DESCRIÇÃO'].str.split(pat='_').map(\n",
    "        lambda x: [i for i in x if i not in ['E', 'M', 'A']]).str.join(sep='_')\n",
    "    # Reordenado variáveis\n",
    "    df_melted[['COMPETÊNCIA', 'ESFERA', 'UF',\n",
    "               'TIPO DE REPASSE', 'REPASSE', 'TOTAL']]\n",
    "    # Convertendo coluna \"COMPETÊNCIA\" para datetime\n",
    "    df_melted['COMPETÊNCIA'] = pd.to_datetime(\n",
    "        df_melted['COMPETÊNCIA'], format=f'%Y-%m-%d')\n",
    "    # Gerando tabela final\n",
    "    df_pivoted = pd.pivot_table(data=df_melted, values='TOTAL', index=[\n",
    "                                'ESFERA', 'UF', 'COMPETÊNCIA', 'REPASSE'], columns='TIPO DE REPASSE', aggfunc='sum', fill_value=0).reset_index()\n",
    "    # Adicionando coluna de categoria de repasses\n",
    "    map = {'AFE_EC123': 'Outros',\n",
    "           'Ajuste': 'Outros',\n",
    "           'COUN': 'Outros',\n",
    "           'COUN_VAAF': 'Complementação VAAF',\n",
    "           'COUN_VAAR': 'Complementação VAAR',\n",
    "           'COUN_VAAT': 'Complementação VAAT',\n",
    "           'FPE': 'FPE',\n",
    "           'FPM': 'FPM',\n",
    "           'ICMS': 'ICMS',\n",
    "           'IPI': 'IPI',\n",
    "           'IPVA': 'IPVA',\n",
    "           'ITCMD': 'ITCMD',\n",
    "           'ITR': 'ITR',\n",
    "           'LC8796': 'Outros'}\n",
    "    df_pivoted['CATEGORIA'] = df_pivoted.REPASSE.map(map)\n",
    "    # Convertendo os dados para formato parquet\n",
    "    df_pivoted.to_parquet('./DATASETS/summarized_data.parquet')\n",
    "    return df_pivoted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiu-se a necessidade de reduzir o numero de colunas ao dataset para apendas ['COMPETÊNCIA', 'EC123', 'COUN', 'VAAF', 'VAAR', 'VAAT', 'FPE', 'FPM', 'ICMS', 'IPI', 'IPVA', 'ITCMD', 'ITR', 'LC8796', 'Ajuste', 'UF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet('./DATASETS/consolidated_data.parquet')\n",
    "unique_var = []\n",
    "for item in df.columns.to_list():\n",
    "    var = item.split(sep='_')[-1]\n",
    "    if var not in unique_var:\n",
    "        unique_var.append(var)\n",
    "unique_var.remove('COMPETÊNCIA')\n",
    "unique_var.remove('UF')\n",
    "print(unique_var)\n",
    "print(len(unique_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados 03 (Final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def finally_data(fold: str):\n",
    "    # Leitura dos dados\n",
    "    df = consolidation_data(fold=fold)\n",
    "    # Divisão dos dados por variável numérica\n",
    "    df_list = []\n",
    "    for col in df.columns.to_list():\n",
    "        filter = ['COMPETÊNCIA', 'UF', f'{col}']\n",
    "        data = df[filter]\n",
    "        name = col.split(sep='_')\n",
    "        if ('A' in name) or ('Ajuste' in name):\n",
    "            data['AJUSTES'] = True\n",
    "        else:\n",
    "            data['AJUSTES'] = False\n",
    "        if 'E' in name:\n",
    "            data['ESFERA'] = 'ESTADUAL'\n",
    "        elif 'M' in name:\n",
    "            data['ESFERA'] = 'MUNICIPAL'\n",
    "        else:\n",
    "            data['ESFERA'] = None\n",
    "        data.columns = ['COMPETÊNCIA', 'UF', f'{name[-1]}', 'AJUSTES', 'ESFERA']\n",
    "        data = data[['COMPETÊNCIA', 'UF', 'AJUSTES', 'ESFERA', f'{name[-1]}']]\n",
    "        df_list.append(data)\n",
    "    df_list = df_list[1:-1]\n",
    "    # Agrupamento dos dados\n",
    "    df_base = df_list[0]\n",
    "    for df_temp in df_list[1:]:\n",
    "        col = df_temp.columns[-1]\n",
    "        if col in df_base.columns.to_list():\n",
    "            df_base = pd.merge(df_base, df_temp, on=['COMPETÊNCIA', 'UF', 'AJUSTES', 'ESFERA', col], how='outer')\n",
    "        else:\n",
    "            df_base = pd.merge(df_base, df_temp, on=['COMPETÊNCIA', 'UF', 'AJUSTES', 'ESFERA'], how='outer')\n",
    "    # Tratamento de valores ausentes\n",
    "    df_base.fillna(0, inplace=True)\n",
    "    # Tratamento de constantes \n",
    "    # - (Não foram identificadas constantes entre os dados)\n",
    "    # # Tratamento de duplicados\n",
    "    df_base.drop_duplicates(inplace=True)\n",
    "    # Adição da coluna total\n",
    "    df_base['TOTAL'] = df_base.sum(axis='columns', numeric_only=True)\n",
    "    # Arquivamento dos dados\n",
    "    df_base.to_parquet('./DATASETS/finally_data.parquet')\n",
    "    return df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMPETÊNCIA</th>\n",
       "      <th>UF</th>\n",
       "      <th>AJUSTES</th>\n",
       "      <th>ESFERA</th>\n",
       "      <th>EC123</th>\n",
       "      <th>COUN</th>\n",
       "      <th>VAAF</th>\n",
       "      <th>VAAR</th>\n",
       "      <th>VAAT</th>\n",
       "      <th>FPE</th>\n",
       "      <th>FPM</th>\n",
       "      <th>ICMS</th>\n",
       "      <th>IPI</th>\n",
       "      <th>IPVA</th>\n",
       "      <th>ITCMD</th>\n",
       "      <th>ITR</th>\n",
       "      <th>LC8796</th>\n",
       "      <th>Ajuste</th>\n",
       "      <th>TOTAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>AC</td>\n",
       "      <td>False</td>\n",
       "      <td>ESTADUAL</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>AC</td>\n",
       "      <td>False</td>\n",
       "      <td>ESTADUAL</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>AC</td>\n",
       "      <td>False</td>\n",
       "      <td>ESTADUAL</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>AC</td>\n",
       "      <td>False</td>\n",
       "      <td>ESTADUAL</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>AC</td>\n",
       "      <td>False</td>\n",
       "      <td>ESTADUAL</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3,548.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3,548.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  COMPETÊNCIA  UF  AJUSTES    ESFERA  EC123  COUN  VAAF  VAAR  VAAT  FPE  FPM  \\\n",
       "0  2007-01-01  AC    False  ESTADUAL   0.00  0.00  0.00  0.00  0.00 0.00 0.00   \n",
       "1  2007-01-01  AC    False  ESTADUAL   0.00  0.00  0.00  0.00  0.00 0.00 0.00   \n",
       "2  2007-01-01  AC    False  ESTADUAL   0.00  0.00  0.00  0.00  0.00 0.00 0.00   \n",
       "3  2007-01-01  AC    False  ESTADUAL   0.00  0.00  0.00  0.00  0.00 0.00 0.00   \n",
       "4  2007-01-01  AC    False  ESTADUAL   0.00  0.00  0.00  0.00  0.00 0.00 0.00   \n",
       "\n",
       "   ICMS      IPI  IPVA  ITCMD  ITR  LC8796  Ajuste    TOTAL  \n",
       "0  0.00     0.00  0.00   0.00 0.00    0.00    0.00     0.00  \n",
       "1  0.00     0.00  0.00   0.00 0.00    0.00    0.00     0.00  \n",
       "2  0.00     0.00  0.00   0.00 0.00    0.00    0.00     0.00  \n",
       "3  0.00     0.00  0.00   0.00 0.00    0.00    0.00     0.00  \n",
       "4  0.00 3,548.46  0.00   0.00 0.00    0.00    0.00 3,548.46  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base = finally_data('./RAW_DATAS')\n",
    "df_base.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atualização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualização dos dados\n",
    "def upgrade_data(fold, update=False):\n",
    "    if update == True:\n",
    "        try:\n",
    "            download_all_excel_datas(destiny_fold=fold)\n",
    "        except:\n",
    "            print('Erro ao efetuar download!')\n",
    "    try:\n",
    "        consolidation_data(fold=fold)\n",
    "        summarization_data(fold=fold)\n",
    "        finally_data(fold=fold)\n",
    "    except:\n",
    "        print('Erro ao gerar datasets!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo 2024 desatualizado, refazendo download.\n",
      "Erro ao efetuar download!\n"
     ]
    }
   ],
   "source": [
    "upgrade_data('./RAW_DATAS', True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
